{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avirmani2024/NLP-Project-/blob/master/Aditya_Virmani_lp_Review_Sentiment_Classification_Using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLhCiU3Evm6"
      },
      "source": [
        "# Yelp Review Sentiment Classification Project Using NLP\n",
        "\n",
        "In this project, I will build a classifier that can predict how a user feels (positively or negatively) about a given restaurant from their review. This is an example of **sentiment analysis**: being able to quantify an individual's opinion about a particular topic merely from the words they use.\n",
        "\n",
        "\n",
        "In this notebook, we'll:\n",
        "\n",
        "\n",
        "*   Explore the Yelp review dataset\n",
        "*   Preprocess and vectorize our text data for NLP\n",
        "*   Train a sentiment analysis classifier with logistic regression\n",
        "*    Explore and improve our model\n",
        "*   Train a model with word embeddings\n",
        "\n",
        "\n",
        "Let's dive in!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jS5ThMCEvnC"
      },
      "source": [
        "#@title Import our libraries (this may take a minute or two)\n",
        "import pandas as pd   # Great for tables (google spreadsheets, microsoft excel, csv).\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "import wordcloud\n",
        "import os # Good for navigating your computer's files\n",
        "import sys\n",
        "pd.options.mode.chained_assignment = None #suppress warnings\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!python -m spacy download en_core_web_md\n",
        "import en_core_web_md\n",
        "text_to_nlp = spacy.load('en_core_web_md')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsF8tioZLicU"
      },
      "source": [
        "#@title Import our data\n",
        "\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket/yelp_final.csv\"\n",
        "\n",
        "# If you run into any errors please uncomment and load the dataset below:\n",
        "\n",
        "##!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%203%20-%20NLP/yelp_final.csv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ267zCBOjet"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BLs_2JkEvnw"
      },
      "source": [
        "First we read in the file containing the reviews and take a look at the data available to us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dZ_lymcN_K9"
      },
      "source": [
        "# read our data in using 'pd.read_csv('file')'\n",
        "yelp_full = pd.read_csv('yelp_final.csv')\n",
        "yelp_full.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB1yKcUtcpg9"
      },
      "source": [
        "needed_columns = ['stars','text']\n",
        "yelp = yelp_full[needed_columns]\n",
        "yelp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MExj8roOEvog"
      },
      "source": [
        "The text column is the one we are primarily focused with. Let's take a look at a few of these reviews to better understand our problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la3rUPKgEvoi"
      },
      "source": [
        "#@title Check out the text in differently rated reviews\n",
        "num_stars =  1#@param {type:\"integer\"}\n",
        "\n",
        "for t in yelp[yelp['stars'] == num_stars]['text'].head(20).values:\n",
        "    print (t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQHod14KEvoz"
      },
      "source": [
        "#### Word Clouds\n",
        "\n",
        "Another way to take a look at the most prominent words in any given star rating is through the use of word clouds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtMnf1zLEvo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "781b750e-167c-467e-df66-e08a4730b3fc"
      },
      "source": [
        "#@title Word cloud for differently rated reviews\n",
        "num_stars =  2#@param {type:\"integer\"}\n",
        "this_star_text = ''\n",
        "for t in yelp[yelp['stars'] == num_stars]['text'].values: # form field cell\n",
        "    this_star_text += t + ' '\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_text(this_star_text)\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03de69f8d2bd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_stars\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m2\u001b[0m\u001b[0;31m#@param {type:\"integer\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthis_star_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myelp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myelp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_stars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# form field cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mthis_star_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'yelp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn4v3upxEvpL"
      },
      "source": [
        "**What are the differences between the reviews that have 1, 2, 3, 4, and 5 stars?**\n",
        "\n",
        "Any surprising similarities?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dArbYofKN206"
      },
      "source": [
        "# Preparing Our Data for Machine Learning\n",
        "\n",
        "Of course, it's much more efficient to use machine learning to analyze our text than try to create rules by hand!\n",
        "\n",
        "We'll need to prepare our data to use logistic regression. First, let's prepare our output column:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bwasn11BfD4"
      },
      "source": [
        "### Exercise: Preparing to Classify\n",
        "We're going to try to predict the sentiment - **positive** or **negative** - based on a review's text.\n",
        "\n",
        "In order to reduce our problem to a **binary classification** (two classes) problem, we will:\n",
        "\n",
        " - label 4 and 5 star reviews as 'good'\n",
        " - label 1, 2, 3 star reviews as 'bad'\n",
        "\n",
        "Please complete the function below and run it to create a new `is_good_review` column!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck4iX6PITzHS"
      },
      "source": [
        "def is_good_review(num_stars):\n",
        "    if num_stars > 3: ### YOUR CODE HERE\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "yelp['is_good_review'] = yelp['stars'].apply(is_good_review)\n",
        "yelp.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8raBKzTEvpM"
      },
      "source": [
        "## Text Preprocessing: A Preview\n",
        "\n",
        "Now, the trickier part: preparing our text input.\n",
        "\n",
        "We'll need a few steps to preprocess our text and represent it numerically. **Why do we need to represent our text as numbers?**\n",
        "\n",
        "We'll talk through all the steps here, then use a single function to implement them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pby7LlwhEvpN"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "First of all, we would like to **tokenize** each review: convert it from a single string into a list of words. Enter some example text into the cell below to see the tokenized version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XOaa1uEEvpY"
      },
      "source": [
        "#@title Basic tokenization example\n",
        "example_text = \"All the people I spoke to were super nice and very welcoming.\" #@param {type:\"string\"}\n",
        "tokens = word_tokenize(example_text)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKCP5Q_LEvpg"
      },
      "source": [
        "## Stopwords\n",
        "\n",
        "Next, let's remove **stopwords**: words which are there to provide grammatical structure, but don't give us much information about a review's sentiment.\n",
        "\n",
        "Edit the cell below to see if we're considering a given word as a stopword! Do you agree with the results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqq4w-ZrEvpj"
      },
      "source": [
        "#@title Check if a word is a stop word\n",
        "example_word = \"fifteen\" #@param {type:'string'}\n",
        "if example_word.lower() in STOP_WORDS:\n",
        "  print ('\"' + example_word + '\" is a stop word.')\n",
        "else:\n",
        "  print ('\"' + example_word + '\" is NOT a stop word.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vubl4ejEvpv"
      },
      "source": [
        "We're going to remove these stopwords from the user reviews.\n",
        "\n",
        "Tokenization and removal of stop words are universal to nearly every NLP application. In some cases, additional cleaning may be required (for example, removal of proper nouns, removal of digits) but we can build a text preprocessing function with these \"base\" cleaning steps.\n",
        "\n",
        "Putting all these together, we can come up with a text cleaning function that we can apply to all of our reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfIUrRtEWr3H"
      },
      "source": [
        "## Vectors\n",
        "\n",
        "Finally, we'll need to convert our text to **vectors**, or lists of numbers. We'll start off doing this with Bag of Words, but we'll talk about another approach later!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43hbR0vha7E3"
      },
      "source": [
        "### Bag of Words\n",
        "\n",
        "In a **bag of words** approach, we count how many times each word was used in each review.\n",
        "\n",
        "Suppose we want to represent two **reviews**:\n",
        "- \"The food was great. The ambience was also great.\"\n",
        "- \"Great ambience, but not great food!\"\n",
        "\n",
        "First we define our vocabulary. This is *each unique word* in the review. So our **vocabulary** is:\n",
        "- [also, ambience, but, food, great, not, the, was].\n",
        "\n",
        "Next, we count up how many times each word was used! (You can also think of this as adding up one-hot encodings.)\n",
        "\n",
        "Our reviews are encoded as:\n",
        "- **First review:** [1, 1, 0, 1, 2, 0, 2, 2].\n",
        "- **Second review:** [0, 1, 1, 1, 2, 1, 0, 0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbFU78B5bXka"
      },
      "source": [
        "## Preprocessing Our Text in Action\n",
        "\n",
        "Let's use bag-of-words to prepare our data!\n",
        "\n",
        "First, let's select our input *X* and output *y*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t6HQm1vEvrQ"
      },
      "source": [
        "X_text = yelp['text']\n",
        "y = yelp['is_good_review']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhRyg_YEeA5t"
      },
      "source": [
        "Now, let's prepare our data! First, we'll use CountVectorizer, a useful tool from Scikit-learn, to:\n",
        "*   Tokenize our reviews\n",
        "*   Remove stopwords\n",
        "*   Prepare our vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSQAeKjAiXJ"
      },
      "source": [
        "#@title Initialize the text cleaning function { display-mode: \"form\" }\n",
        "def tokenize(text):\n",
        "    clean_tokens = []\n",
        "    for token in text_to_nlp(text):\n",
        "        if (not token.is_stop) & (token.lemma_ != '-PRON-') & (not token.is_punct): # -PRON- is a special all inclusive \"lemma\" spaCy uses for any pronoun, we want to exclude these\n",
        "            clean_tokens.append(token.lemma_)\n",
        "    return clean_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfDtH-XTSrCK"
      },
      "source": [
        "The cell below will take a moment! **Can you guess what `max_features` is for?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blZ7RJ2zEvrU"
      },
      "source": [
        "bow_transformer = CountVectorizer(analyzer=tokenize, max_features=800).fit(X_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaheGj_RmKW7"
      },
      "source": [
        "Now, we can see our entire vocabulary! Can you guess what the numbers represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TjdgYVxmKgd"
      },
      "source": [
        "bow_transformer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGEf8h1lEvrY"
      },
      "source": [
        "The number represents the **index** (alphabetical position) of a word in the vocabulary.\n",
        "\n",
        "By the way, how many words do we have?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upN1gxm5Evrb"
      },
      "source": [
        "len(bow_transformer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkN4E-QCTFom"
      },
      "source": [
        "It's the same as `max_features`! Is that a coincidence? What's the point of `max_features`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsFa7Nu5Evr4"
      },
      "source": [
        "Now that our vocabulary is ready, we can **transform** each review into a bag of words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRJJe2HGEvr6"
      },
      "source": [
        "X = bow_transformer.transform(X_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu6FEly_UMFC"
      },
      "source": [
        "Finally, we've converted our reviews to numerical data that we can use in a logistic regression!\n",
        "\n",
        "We can see what `X` looks like by printing it out as a DataFrame. **How long is each review's vector?** Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdeKo8ZQTiOu"
      },
      "source": [
        "pd.DataFrame(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8AUxyLHEvr_"
      },
      "source": [
        "# Creating a Baseline Classifier\n",
        "\n",
        "Now, back to our sentiment analysis problem! Our data is ready for machine learning.\n",
        "\n",
        "Our classification problem is a classic two-class classification problem, and so we will use the tried-and-tested **Logistic Regression** machine learning model.\n",
        "\n",
        "As always, we'll start by setting aside testing and training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PThy6pNUEvsA"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42rl41sUXr0-"
      },
      "source": [
        "###Training The Model\n",
        "Now, we can create and train our model! Please **fill in the code to train (or *fit*) your model**.\n",
        "\n",
        "(Need a hint? Refer to last time's notebook or Scikit-learn documentation if needed.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIpbdNZwgRTn"
      },
      "source": [
        "logistic_model = LogisticRegression()\n",
        "\n",
        "logistic_model.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hFMR7NUV84D"
      },
      "source": [
        "###Testing The Model\n",
        "Now, let's evaluate our model's accuracy! Your model needs to **predict** the sentiment, and then you'll **calculate the accuracy** using `accuracy_score`. **Which dataset** should you use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVdf84tuWQwM"
      },
      "source": [
        "y_pred = logistic_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print (accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zct-JZPQaXno"
      },
      "source": [
        "Model has been trained and tested! It's not perfect, but a whole lot better than a coin flip :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiUFnTXrased"
      },
      "source": [
        "###Trying Out The Reviews\n",
        "\n",
        "Accuracy only tells us so much! It's often useful to figure out **what sorts** of mistakes your model makes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuR1VWWEvsX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "3bf472b2-aac0-4d6d-e5e9-25e6a18b2da9"
      },
      "source": [
        "#@title Entering a review to see the model's classification\n",
        "example_review = \"This restaurant is great\" #@param {type:'string'}\n",
        "prediction = logistic_model.predict(bow_transformer.transform([example_review]))\n",
        "\n",
        "if prediction:\n",
        "  print (\"This was a GOOD review!\")\n",
        "else:\n",
        "  print (\"This was a BAD review!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f06004795456>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Entering a review to see the model's classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexample_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This restaurant is great\"\u001b[0m \u001b[0;31m#@param {type:'string'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_review\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'logistic_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILybPDLAaphw"
      },
      "source": [
        "# Exploring The Model\n",
        "\n",
        "Let's explore your model in more depth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsz6RA7qTS0O"
      },
      "source": [
        "###Viewing the Model Weights\n",
        "Now let's look at the weights of our model! Remember that logistic regression works by multiplying all of our inputs by weights, summing the results, and then converting that raw number to a probability score (between 0 and 1)! This means that we can look at the weight assigned to each input (or in our case word) to figure out how that word impacts our model!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src='https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%203%20-%20NLP/Linear_logistic_regression.jpg' >"
      ],
      "metadata": {
        "id": "N8XL3yam5_XQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dictionary is a data structure that stores information in key:value pairs. You retrieve the value of a given key from a dictionary dict by calling \"dict[key]\" which returns value. Similary, you can assign a value to a key by calling \"dict[key]=value\".<br><br> In the case of NLP, we need to store our vocabulary in a dictionary, where the key is the word in string format and the value is the index of that word. So, to find the index of a word in our vocab dictionary we would call \"vocab[word]\", which would then return the index. Similarly, we can assign a word an index by calling \"vocab[word]=index\"."
      ],
      "metadata": {
        "id": "R2AOx-WqiqT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finishing the function, It takes in the following:\n",
        "\n",
        "* `word`: a word from our vocabulary\n",
        "* `model`: the logistic regression model whose weights we want to query.\n",
        "* `vocab_dict`: a dictionary containg word:index as the key:value pair.\n",
        "\n",
        "\n",
        "\n",
        "The function should then return the weight that the logistic regression model has learned for the word in question. The model weights (also called coefficients) can be accessed by calling `model.coef_[0][id]`, where `id` is the index of the vocab word in question.)\n",
        "\n"
      ],
      "metadata": {
        "id": "2mbVUkzXfPTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_weight(word,model,vocab_dict):\n",
        "\n",
        "\n",
        "  if word in vocab_dict:\n",
        "\n",
        "    index=vocab_dict[word]\n",
        "    weight=model.coef_[0][index]\n",
        "\n",
        "    return weight\n",
        "  else:\n",
        "    return \"That word is not in our Vocabulary!\""
      ],
      "metadata": {
        "id": "nwT_d9822rIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input a sentence to see the weights of each word!\n",
        "sentence = \"this is a good place\" #@param {type:'string'}\n",
        "words=tokenize(sentence)\n",
        "temp_weight_dict={}\n",
        "for word in words:\n",
        "  weight=get_word_weight(word,logistic_model,bow_transformer.vocabulary_)\n",
        "  temp_weight_dict[word]=weight\n",
        "print(temp_weight_dict,\"bias:  \"+str(logistic_model.intercept_[0]))\n"
      ],
      "metadata": {
        "id": "BWGttdpajfV7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}